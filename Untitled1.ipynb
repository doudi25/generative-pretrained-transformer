{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doudi25/generative-pretrained-transformer/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pg9qX-RluR0T"
      },
      "outputs": [],
      "source": [
        "with open('Hugo.txt', 'r') as f:\n",
        "    data=f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH9VJhqYvRm4",
        "outputId": "f823452a-022f-4d16-e2df-8f601996c2f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars=sorted(list(set(data)))\n",
        "vocab_size=len(chars)\n",
        "print(vocab_size)\n",
        "print(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaNFYY6yvTjQ",
        "outputId": "36a6ccf8-95eb-471c-b546-477f08331523",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105\n",
            "['\\n', '\\x0c', ' ', '!', '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '«', '°', '»', '½', 'À', 'Â', 'Ç', 'È', 'É', 'Ê', 'Ô', 'à', 'â', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'î', 'ï', 'ñ', 'ô', 'ù', 'û', 'ü', 'Œ', 'œ', '–', '’']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str_to_int={ch:i for i,ch in enumerate(chars)}\n",
        "int_to_str={i:ch for i,ch in enumerate(chars)}\n",
        "encoder= lambda s : [str_to_int[char] for char in s]\n",
        "decoder= lambda lis : ''.join([int_to_str[i] for i in lis])\n",
        "print(encoder('my name is abdou'))\n",
        "print(decoder(encoder('my name is abdou')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZQUcl3nvV3W",
        "outputId": "27ccbfe6-c221-4974-842e-368137ef985c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[61, 73, 2, 62, 49, 61, 53, 2, 57, 67, 2, 49, 50, 52, 63, 69]\n",
            "my name is abdou\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data=torch.tensor(encoder(data),dtype=torch.long)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AMeTjo8vYWR",
        "outputId": "4955a16c-b99d-4084-8e6d-533129684624"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  0,   0,   1,  32,   0,  35,   9,   2,  35,  73,  66,  57,  53,  60,\n",
            "          9,   0,  28,  62,   0,  12,  19,  12,  16,   7,   0,  35,   9,   2,\n",
            "         26,  56,  49,  66,  60,  53,  67,   8,  29,  66,  49,  62,  89,  63,\n",
            "         57,  67,   8,  25,  57,  53,  62,  70,  53,  62,  69,   0,  35,  73,\n",
            "         66,  57,  53,  60,   2,  91,  68,  49,  57,  68,   2,  91,  70,  92,\n",
            "         65,  69,  53,   2,  52,  53,   2,  27,  57,  55,  62,  53,   9,   2,\n",
            "         26, 104,  91,  68,  49,  57,  68,   2,  69,  62,   2,  70,  57,  53,\n",
            "         57,  60,  60,  49,  66,  52,   0,  52, 104,  53,  62,  70,  57,  66,\n",
            "         63,  62,   2,  67,  63,  57,  72,  49,  62,  68,  53,   8,  65,  69,\n",
            "         57,  62,  74,  53,   2,  49,  62,  67,   2,  22,   2,  57,  60,   2,\n",
            "         63,  51,  51,  69,  64,  49,  57,  68,   2,  60,  53,   0,  67,  57,\n",
            "         90,  55,  53,   2,  52,  53,   2,  27,  57,  55,  62,  53,   2,  52,\n",
            "         53,  64,  69,  57,  67,   2,  12,  19,  11,  17,   9,   0,  39,  69,\n",
            "         63,  57,  65,  69,  53,   2,  51,  53,   2,  52,  91,  68,  49,  57,\n",
            "         60,   2,  62,  53,   2,  68,  63,  69,  51,  56,  53,   2,  53,  62,\n",
            "          2,  49,  69,  51,  69,  62,  53,   0,  61,  49,  62,  57,  90,  66,\n",
            "         53,   2,  49,  69,   2,  54,  63,  62,  52,   2,  61,  92,  61,  53,\n",
            "          2,  52,  53,   2,  51,  53,   2,  65,  69,  53,   2,  62,  63,  69,\n",
            "         67,   2,  49,  70,  63,  62,  67,   2,  86,   0,  66,  49,  51,  63,\n",
            "         62,  68,  53,  66,   7,   2,  57,  60,   2,  62, 104,  53,  67,  68,\n",
            "          2,  64,  53,  69,  68,   8,  92,  68,  66,  53,   2,  64,  49,  67,\n",
            "          2,  57,  62,  69,  68,  57,  60,  53,   7,   2,  62,  53,   2,  54,\n",
            "         99,  68,   8,  51,  53,   0,  65,  69,  53,   2,  64,  63,  69,  66,\n",
            "          2,  92,  68,  66,  53,   2,  53,  72,  49,  51,  68,   2,  53,  62,\n",
            "          2,  68,  63,  69,  68,   7,   2,  52, 104,  57,  62,  52,  57,  65,\n",
            "         69,  53,  66,   2,  57,  51,  57,   2,  60,  53,  67,   0,  50,  66,\n",
            "         69,  57,  68,  67,   2,  53,  68,   2,  60,  53,  67,   2,  64,  66,\n",
            "         63,  64,  63,  67,   2,  65,  69,  57,   2,  49,  70,  49,  57,  53,\n",
            "         62,  68,   2,  51,  63,  69,  66,  69,   2,  67,  69,  66,   2,  67,\n",
            "         63,  62,   0,  51,  63,  61,  64,  68,  53,   2,  49,  69,   2,  61,\n",
            "         63,  61,  53,  62,  68,   2,  63,  98,   2,  57,  60,   2,  91,  68,\n",
            "         49,  57,  68,   2,  49,  66,  66,  57,  70,  91,   2,  52,  49,  62,\n",
            "         67,   2,  60,  53,   0,  52,  57,  63,  51,  90,  67,  53,   9,   2,\n",
            "         44,  66,  49,  57,   2,  63,  69,   2,  54,  49,  69,  72,   7,   2,\n",
            "         51,  53,   2,  65,  69, 104,  63,  62,   2,  52,  57,  68,   2,  52,\n",
            "         53,  67,   2,  56,  63,  61,  61,  53,  67,   0,  68,  57,  53,  62,\n",
            "         68,   2,  67,  63,  69,  70,  53,  62,  68,   2,  49,  69,  68,  49,\n",
            "         62,  68,   2,  52,  53,   2,  64,  60,  49,  51,  53,   2,  52,  49,\n",
            "         62,  67,   2,  60,  53,  69,  66,   2,  70,  57,  53,   2,  53,  68,\n",
            "          0,  67,  69,  66,  68,  63,  69,  68,   2,  52,  49,  62,  67,   2,\n",
            "         60,  53,  69,  66,   2,  52,  53,  67,  68,  57,  62,  91,  53,   2,\n",
            "         65,  69,  53,   2,  51,  53,   2,  65,  69, 104,  57,  60,  67,   2,\n",
            "         54,  63,  62,  68,   9,   0,  35,   9,   2,  35,  73,  66,  57,  53,\n",
            "         60,   2,  91,  68,  49,  57,  68,   2,  54,  57,  60,  67,   2,  52,\n",
            "        104,  69,  62,   2,  51,  63,  62,  67,  53,  57,  60,  60,  53,  66,\n",
            "          2,  49,  69,   2,  64,  49,  66,  60,  53,  61,  53,  62,  68,   0,\n",
            "         52, 104,  24,  57,  72,   2,  22,   2,  62,  63,  50,  60,  53,  67,\n",
            "         67,  53,   2,  52,  53,   2,  66,  63,  50,  53,   9,   2,  37,  62,\n",
            "          2,  51,  63,  62,  68,  49,  57,  68,   2,  52,  53,   2,  60,  69,\n",
            "         57,   2,  65,  69,  53,   0,  67,  63,  62,   2,  64,  90,  66,  53,\n",
            "          7,   2,  60,  53,   2,  66,  91,  67,  53,  66,  70,  49,  62,  68,\n",
            "          2,  64,  63,  69,  66,   2,  56,  91,  66,  57,  68,  53,  66,   2,\n",
            "         52,  53,   2,  67,  49,   2,  51,  56,  49,  66,  55,  53,   7,   0,\n",
            "         19,   0,   0,   1,  60, 104,  49,  70,  49,  57,  68,   2,  61,  49,\n",
            "         66,  57,  91,   2,  52,  53,   2,  54,  63,  66,  68,   2,  50,  63,\n",
            "         62,  62,  53,   2,  56,  53,  69,  66,  53,   7,   2,  86,   2,  52,\n",
            "         57,  72,   8,  56,  69,  57,  68,   2,  63,  69,   0,  70,  57,  62,\n",
            "         55,  68,   2,  49,  62,  67,   7,   2,  67,  69,  57,  70,  49,  62,\n",
            "         68,   2,  69,  62,   2,  69,  67,  49,  55,  53,   2,  49,  67,  67,\n",
            "         53,  74,   2,  66,  91,  64,  49,  62,  52,  69,   2,  52,  49,  62,\n",
            "         67,   0,  60,  53,  67,   2,  54,  49,  61,  57,  60,  60,  53,  67,\n",
            "          2,  64,  49,  66,  60,  53,  61,  53,  62,  68,  49,  57,  66,  53,\n",
            "         67,   9,   2,  26,  56,  49,  66,  60,  53,  67,   2,  35,  73,  66,\n",
            "         57,  53,  60,   7,   0,  62,  63,  62,  63,  50,  67,  68,  49,  62,\n",
            "         68,   2,  51,  53,   2,  61,  49,  66,  57,  49,  55,  53,   7,   2,\n",
            "         49,  70,  49,  57,  68,   7,   2,  52,  57,  67,  49,  57,  68,   8,\n",
            "         63,  62,   7,   2,  50,  53,  49,  69,  51,  63,  69,  64,   0,  54,\n",
            "         49,  57,  68,   2,  64,  49,  66,  60,  53,  66,   2,  52,  53,   2,\n",
            "         60,  69,  57,   9,   2,  32,  60,   2,  91,  68,  49,  57,  68,   2,\n",
            "         50,  57,  53,  62,   2,  54,  49,  57,  68,   2,  52,  53,   2,  67,\n",
            "         49,   2,  64,  53,  66,  67,  63,  62,  62,  53,   7,   0,  65,  69,\n",
            "         63,  57,  65,  69,  53,   2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=data[:int(0.9*len(data))]\n",
        "test_data=data[int(0.9*len(data)):]"
      ],
      "metadata": {
        "id": "cQZTVPS_vaNo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size=64\n",
        "block_size=256\n",
        "n_embed=128\n",
        "nbr_layers=4\n",
        "n_head=4\n",
        "def get_batch(split):\n",
        "  data=train_data if split=='train' else test_data\n",
        "  ix=torch.randint(len(data)-block_size,(batch_size,))\n",
        "  x=torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y=torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "aM3ulf2tvec4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 3e-4\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  out={}\n",
        "  model.eval()\n",
        "  for split in ['train','val']:\n",
        "    losses=torch.zeros(eval_interval)\n",
        "    for k in range(eval_interval):\n",
        "      X,Y=get_batch(split)\n",
        "      logits,loss=model(X,Y)\n",
        "      losses[k]=loss.item()\n",
        "    out[split]=losses.mean()\n",
        "  model.train()\n",
        "  return out\n"
      ],
      "metadata": {
        "id": "m1RJ-Y9avgqD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class Head(nn.Module):\n",
        "  def __init__(self,head_size):\n",
        "    super().__init__()\n",
        "    self.key=nn.Linear(n_embed,head_size,bias=0)\n",
        "    self.query=nn.Linear(n_embed,head_size,bias=0)\n",
        "    self.value=nn.Linear(n_embed,head_size,bias=0)\n",
        "    self.register_buffer('tril',torch.tril(torch.ones(block_size,block_size)))\n",
        "    self.dropout=nn.Dropout(0.2)\n",
        "  def forward(self,x):\n",
        "    B,T,C=x.shape\n",
        "    k=self.key(x)\n",
        "    q=self.query(x)\n",
        "    wei=q @ k.transpose(-2,-1)*(C**-0.5)\n",
        "    wei=wei.masked_fill(self.tril[:T,:T]==0,float('-inf'))\n",
        "    wei=F.softmax(wei,dim=-1)\n",
        "    wei=self.dropout(wei)\n",
        "    v = self.value(x)\n",
        "    out=wei @ v\n",
        "    return out"
      ],
      "metadata": {
        "id": "DWT8w5qPvjGb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embed)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out"
      ],
      "metadata": {
        "id": "4alplWV4vl_u"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self,n_embed):\n",
        "    super().__init__()\n",
        "    self.c_fc=nn.Linear(n_embed,2*n_embed)\n",
        "    self.c_proj=nn.Linear(2*n_embed,n_embed)\n",
        "    self.act_fn=nn.ReLU()\n",
        "    self.dropout=nn.Dropout(0.2)\n",
        "  def forward(self,x):\n",
        "    x=self.c_fc(x)\n",
        "    x=self.c_proj(x)\n",
        "    x=self.act_fn(x)\n",
        "    x=self.dropout(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "onEuYWJ4vpAA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "  def __init__(self,n_embed,n_head):\n",
        "    super().__init__()\n",
        "    head_size=n_embed//n_head\n",
        "    self.sa=MultiHeadAttention(n_head,head_size)\n",
        "    self.ln1=nn.LayerNorm(n_embed)\n",
        "    self.mlp=MLP(n_embed)\n",
        "    self.ln2=nn.LayerNorm(n_embed)\n",
        "  def forward(self,x):\n",
        "    x=x+self.sa(self.ln1(x))\n",
        "    x=x+self.mlp(self.ln2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "kMnL1DP6vqxR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=106\n",
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table=nn.Embedding(vocab_size,n_embed)\n",
        "    self.position_embedding_table=nn.Embedding(block_size,n_embed)\n",
        "    self.blocks=nn.Sequential(*[Block(n_embed,n_head=4) for _ in range(nbr_layers)])\n",
        "    self.ln_f=nn.LayerNorm(n_embed)\n",
        "    self.lm_head=nn.Linear(n_embed,vocab_size)\n",
        "  def forward(self,idx,target=None):\n",
        "    B,T=idx.shape\n",
        "    idx=idx.to(device)\n",
        "    token_embed=self.token_embedding_table(idx)\n",
        "    pos_embed=self.position_embedding_table(torch.arange(T).to(device))\n",
        "    x=token_embed+pos_embed\n",
        "    x=self.blocks(x)\n",
        "    x=self.ln_f(x)\n",
        "    logits=self.lm_head(x)\n",
        "    if target is None:\n",
        "      loss=None\n",
        "    else:\n",
        "      B,T,C=logits.shape\n",
        "      logits=logits.view(B*T,C)\n",
        "      target=target\n",
        "      target=target.to(device)\n",
        "      target=target.view(B*T)\n",
        "      loss=F.cross_entropy(logits,target)\n",
        "    return logits,loss\n",
        "  def generate(self,idx,max_new_tokens):\n",
        "    idx=idx.to(device)\n",
        "    for _ in range(max_new_tokens):\n",
        "      idx_cond=idx[:,-block_size:]\n",
        "      logits,loss=self(idx_cond)\n",
        "      logits=logits[:,-1,:]\n",
        "      probs=F.softmax(logits,dim=-1)\n",
        "      idx_next=torch.multinomial(probs,num_samples=1).clamp(max=vocab_size-1)\n",
        "      idx=torch.cat((idx,idx_next),dim=1)\n",
        "    return idx\n",
        "model=BigramLanguageModel()\n",
        "model.to(device)\n",
        "xb,yb=get_batch('train')\n",
        "xb=xb.to(device)\n",
        "yb=yb.to(device)\n",
        "logits,loss=model(xb,yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "print(decoder(model.generate(idx=torch.zeros((1,1),dtype=torch.long),max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "id": "nhuE7EpKvtVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('algerian_nano_gpt.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcyanrpJvwqu",
        "outputId": "95a5ecfd-136e-46a1-a0ca-861439b41a4c",
        "collapsed": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BigramLanguageModel(\n",
              "  (token_embedding_table): Embedding(106, 128)\n",
              "  (position_embedding_table): Embedding(256, 128)\n",
              "  (blocks): Sequential(\n",
              "    (0): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-3): 4 x Head(\n",
              "            (key): Linear(in_features=128, out_features=32, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=32, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=32, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLP(\n",
              "        (c_fc): Linear(in_features=128, out_features=256, bias=True)\n",
              "        (c_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "        (act_fn): ReLU()\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-3): 4 x Head(\n",
              "            (key): Linear(in_features=128, out_features=32, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=32, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=32, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLP(\n",
              "        (c_fc): Linear(in_features=128, out_features=256, bias=True)\n",
              "        (c_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "        (act_fn): ReLU()\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (2): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-3): 4 x Head(\n",
              "            (key): Linear(in_features=128, out_features=32, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=32, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=32, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLP(\n",
              "        (c_fc): Linear(in_features=128, out_features=256, bias=True)\n",
              "        (c_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "        (act_fn): ReLU()\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (3): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-3): 4 x Head(\n",
              "            (key): Linear(in_features=128, out_features=32, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=32, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=32, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLP(\n",
              "        (c_fc): Linear(in_features=128, out_features=256, bias=True)\n",
              "        (c_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "        (act_fn): ReLU()\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  (lm_head): Linear(in_features=128, out_features=106, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "for j in range(5000):\n",
        "  for i in range(1):\n",
        "    if i % eval_interval == 0:\n",
        "      losses = estimate_loss()  # Define this function as per your requirement\n",
        "      print(f\"step {j}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    xb, yb = get_batch('train')  # Define this function as per your requirement\n",
        "    logits, loss = model(xb, yb)  # Forward pass to get logits and loss\n",
        "\n",
        "    optimizer.zero_grad()  # Clear gradients\n",
        "    loss.backward()  # Backward pass to calculate gradients\n",
        "    optimizer.step()  # Update model parameters"
      ],
      "metadata": {
        "id": "Cgml1Jbiv0qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'algerian_nano_gpt.pth')\n"
      ],
      "metadata": {
        "id": "CJPxix9XwY7Z"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder(model.generate(idx=torch.zeros((1,1),dtype=torch.long),max_new_tokens=200)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKxQEI_zFsnA",
        "outputId": "f509a268-f425-42ac-94f8-62a8c9f62192"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "quoi gens devins arravec de toujoure que se\n",
            "sacril de pointe toute et en quelquées. Prenant\n",
            "du ce la messal qui sont fois sa plus sur Bargs,\n",
            "toute à la vie, était de l’agous les comme de la cette\n",
            "prés\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def generate_text(input):\n",
        "  return decoder(model.generate(idx=torch.zeros((1,1),dtype=torch.long),max_new_tokens=input)[0].tolist())\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=generate_text,\n",
        "    inputs=gr.Slider(minimum=1, maximum=5000, step=1, label=\"Input your max tokens\"), # Use gr.Slider instead of gr.inputs.Number\n",
        "    outputs=gr.Textbox(label=\"Generated tokens\"),\n",
        "    title=\"NanoGPT for Les Misérables Book\")\n",
        "interface.launch(share=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lMzG9J6vSrTs",
        "outputId": "85b4e3be-4613-44f3-c6ef-34d58eb96e13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://088d817ca88d3c5df3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://088d817ca88d3c5df3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "Kri80uojPSRo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}